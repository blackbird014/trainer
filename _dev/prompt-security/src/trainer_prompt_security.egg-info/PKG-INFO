Metadata-Version: 2.4
Name: trainer-prompt-security
Version: 0.1.0
Summary: Security module for protecting against prompt injection attacks
Author: Trainer Project
License: MIT
Keywords: prompt,security,injection,validation,sanitization
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"
Provides-Extra: ml
Requires-Dist: scikit-learn>=1.3.0; extra == "ml"
Provides-Extra: all
Requires-Dist: pytest>=7.0.0; extra == "all"
Requires-Dist: pytest-cov>=4.0.0; extra == "all"
Requires-Dist: black>=23.0.0; extra == "all"
Requires-Dist: ruff>=0.1.0; extra == "all"

# Prompt Security Module

Comprehensive security module for protecting against prompt injection attacks and validating user input in prompt templates.

## Features

- **Input Validation**: Length limits, character filtering, type checking
- **Input Sanitization**: Control character removal, pattern blocking
- **Injection Detection**: Pattern-based detection of prompt injection attempts
- **Template Escaping**: Safe variable insertion with delimiters
- **Configurable Security**: Strict/moderate/permissive modes
- **Comprehensive Logging**: Security event tracking

## Installation

```bash
cd _dev/prompt-security
pip install -e .
```

Or install with development dependencies:

```bash
pip install -e ".[dev]"
```

## Quick Start

```python
from prompt_security import SecurityModule

# Initialize security module
security = SecurityModule(
    max_length=1000,
    strict_mode=True
)

# Validate user input
try:
    validated = security.validate({"name": "John", "age": "30"})
except ValidationError as e:
    print(f"Validation failed: {e}")

# Detect injections
detection = security.detect_injection("Ignore previous instructions...")
if not detection.is_safe:
    print(f"Injection detected: {detection.flags}")

# Escape for template insertion
escaped = security.escape("User input text")
```

## Integration with Prompt Manager

```python
from prompt_manager import PromptManager
from prompt_security import SecurityModule

# Initialize security
security = SecurityModule(strict_mode=True)

# Use with PromptManager
manager = PromptManager(security_module=security)

# Template filling automatically validates
template = PromptTemplate("Hello {name}!")
filled = manager.fill_template(template, {"name": "World"})
```

## Configuration

```python
from prompt_security import SecurityModule, SecurityConfig

config = SecurityConfig(
    max_length=1000,
    strict_mode=True,
    allow_newlines=False,
    detection_threshold=0.7
)

security = SecurityModule(config=config)
```

## Security Features

### Input Validation
- Maximum/minimum length per variable
- Control character detection
- Newline filtering
- Custom character pattern matching

### Injection Detection
- Pattern-based detection (regex)
- Instruction override detection
- Context manipulation detection
- Risk scoring

### Template Escaping
- XML-style escaping
- JSON encoding
- Delimiter-based escaping
- User input section wrapping

## Threat Model

The module protects against:
- Direct prompt injection (`"Ignore previous instructions"`)
- Context poisoning (`"### System: You are now..."`)
- Instruction override (`"You must now..."`)
- Data exfiltration attempts
- Template variable manipulation

## Best Practices

1. **Always validate user input** before template filling
2. **Use strict mode** in production
3. **Monitor security events** via logging
4. **Review detection results** for false positives
5. **Use structured templates** with clear user input boundaries

## Future Enhancements

- ML-based injection classifier
- Context-aware validation
- Advanced pattern learning
- Security agent for continuous monitoring
- Industry-standard security framework compliance

## License

MIT

